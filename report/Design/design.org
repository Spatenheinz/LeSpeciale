* Proof Carrying Code in the Kernel
:PROPERTIES:
:CUSTOM_ID: sec:pccandebpf
:END:

Before we can get a grasp of what it takes to make PCC work in the kernel,
one must first have a better understanding of what is actually happening in the verifier.
In Section \ref{sec:verifier} we take a "deepdive" into the inner workings of the verifier.
The purpose of this is to create a bridge between eBPF and PCC and to further emphasize why
we should investigate other methods of verification than the static analysis that exist at the moment.
In Section \ref{sec:ebpfandpcc} we describe an overall design to how we can use PCC in the Linux kernel.
In this section we further argue for some general design decisions taken in the process of creating the proof checking part of the PCC system.

** Spelunking the eBPF verifier
:PROPERTIES:
:CUSTOM_ID: sec:verifier
:END:
#+include: ebpf.org

** eBPF and PCC
:PROPERTIES:
:CUSTOM_ID: sec:ebpfandpcc
:END:
From the description of PCC in \ref{sec:pcc} and the description of the eBPF subsystem above,
it should be clear that eBPF and the verifier has some clear similarities with PCC.
eBPF present a clear set of security policies, which must be followed to load programs into the kernel.
Likewise there is a clear distinction between the user space and kernel space or in PCC terminology between code producer and consumer.
Where the current eBPF loading system differs from the PCC described by Necula is where the responsibility lies.
Considering the pipeline we have:

1. *Compilation and Certification*: For PCC the untrusted program is both compiled and a certificate
   for safety policy compliance is generated by the code producer.
   eBPF does not really "do" anything at this stage as source code is passed directly to the kernel using the syscall, and then possibly JIT compiled later in the pipeline.

2. *Verification of certificate*: In PCC the consumer will check the validity of the certification wrt. the safety policy and compatability between the code and the certificate.
   eBPF will have to do a similar check but directly on the eBPF program.
   From a purely complexity wise standpoint verification by checking a proof should not be any harder than performing the static analysis done by the verifier.
3. *Running*: In both structures, once a certificate is checked the program is free to use possibly many times.

So if they are so similar in structure, why would we want to replace the verifier with an actual proof checker?
As already mentioned the eBPF verifier has been prone to bugs in the past, and the code for the verifier is charaterized by patching of these bugs, instead of implementing a proved sound abstract interpretation.
Having a proof checker that implements a sound approach to proof checking will both give a higher certainty in safety as well as more accepted programs, because a proof checker does not have to be as conservative as static analysis.

*** How to add PCC to eBPF
To realize PCC in the Linux kernel we must extend it in some way.
There are mainly four ways we can extend the Linux kernel by the documentation\cite{kerneldoc}.
1. If an operation can be achieved using one of the many filesystems already present in the kernel, then it should do so.
2. For operations that are device specific, we should consider a LKM.
3. If new functionality is to the kernel it should be in the form of a syscall.
4. If strictly necessary a system call should be modified, but its API should be the same.

The first two options are not really viable solutions for a PCC infrastructure,
since it would require plugging into the subsystem in some way, and this interaction in general seem to break many responsibility patterns and would still require modifying the ~bpf~ syscall.
Option 3 likewise imposes a responsibility mismatch. All interactions with the eBPF subsystem goes through the syscall, and having separate system calls to validate the code and load it is not optimal.
Likewise the proof checker cannot substitute the entire loading process but only the verifier, and probably not all of the checks can be completely removed.
For instance we might still require capabilities to be checked seperately, but include memory alignment in the verification condition for the program. On the other hand capabilities are just boolean flags, which can easily be
represented in logic. Such design decisions would require more experimentation.

The most optimal solution would be to modify the ~bpf~ syscall directly.
We can here also get partial transition by adding the feature of a proof checker and give the proof as part of the ~attr~ struct for the syscall.
Then when confidence in the proof checker is high enough the verfier can be phased out.

*** Certifications
:PROPERTIES:
:CUSTOM_ID: sec:certifications
:END:
As previously mentioned we only implement part of PCC in this report,
and this implementation should also just be seen as a prototype.

For the general architecture we consider a certification format based on formal logic of verification conditions based on predicate transformer semantics\cite{predicatetransformer}.
This is particularly useful for automatic generation of formulas to describe programs.
The process amount to showing the satisfiability of the negated formula, since this gives validity.
The process of proving the validity of such a verification condition however is not a simple task
and is, dependending on the logic, undecidable.
Checking the satisfiability of a formula can be done by a Satisfiability Modulo Theories (SMT) solver.
In some SMT solvers it is possible to extract a proof that a certain formula is satisfiable.
We have in this work considered two output formats/languages, Alethe\cite{alethe} and Logical Framework with Side Conditions (LFSC)\cite{lfsc},
supported by the CVC5 SMT solver.
I will briefly describe why I have chosen to use the LFSC language over Alethe.

Both formats follow the LISP family of languages and is therefore simple to parse.

Alethe is designed to be easily readable by humans and strutured as a box style proof, with subproofs, conclusions etc. which makes understanding the proofs easy.
This is not a property necessary for a PCC architecture where we want to automate the entire process, and dont care about the plain text format, but in fact rather would want a bytecode format.
By this construction the Alethe format provides a set of 91 inference rules\cite{alethe},
on which proofs are built,
As an example rule 20 is reflection often denoted as ~refl~ which states equality after applying a context.
This entails that an implementation must implement all rules necessary for a security policy and will not be as easily extended in the future as part of a Linux kernel.

LFSC on the otherhand is a metaframework that exploits the Curry-Howard isomorphism by dependent type theory.
This metaframework allows for the security policy to be established by signatures, which encodes similar rules to the ones defined in Alethe.
The metaframework allow us to implement a simple algorithm for typechecking signatures and verification conditions, which once defined does not have to be changed.
New functionality can then easily be added by new signatures.
Furthermore this approach can move bugs out of the in-kernel certifier and into the specification.
This will enable system administrators to quickly deploy fixes for a bug, by not allowing specific faulty signatures.

Another important feature of a certification checker in the kernel is that it should be both memory and time efficient.
It is hard to consider both time and memory used of the two languages without actually implementing both of them.
But if we consider the amount of code require for the two formats then there exists a rust implementation for an Alethe proof checker called carcara\cite{carcara}.
This implementation is ~13500 lines of code, and while not all rules may be necesssary this specific implementation does not even support all theories present in CVC5, such as bitvectors.
Bitvectors are an essential part of an eBPF verification condition since operations are bitwise.
It is however worth noting that the Alethe format allows bitvectors and it is only carcara that does not handle them.
LFSC has a proof checker written in C++ and its code is merely 5000 lines\cite{lfscc}, and new signatures requires no modification to the code.
In general the takeaway from this is that an Alethe proof checker is far more complex to implement and maintain than an LFSC proof checker.

Overall LFSC provides a better basis for the use case.
When using LFSC in the proof checker we suggest that the process of checking that the eBPF program to be loaded correspond to the proof is done by generating a verification condition and then comparing it to the assertions in the proof.
The specific formula that needs to be proved is directly imbedded in an LFSC proof.
Hence we suggest that an in kernel verification condition generator generates formulas that can easily be compared with the formula from the proof.
This also means that we can reuse some of the code used to implement the proof checker for the VC generation.

# ** Deciding on a format
# #+include: proof_comparison.org
