* Proof Carrying Code in the Kernel
:PROPERTIES:
:CUSTOM_ID: sec:pccandebpf
:END:

Before we can get a grasp of what it takes to make PCC work in the kernel,
one must first have a better understanding of what is actually happening in the verifier.
In Section \ref{sec:verifier} we take a "deep dive" into the inner workings of the verifier.
The purpose of this is to create a bridge between eBPF and PCC and to further emphasize why
we should investigate other methods of verification than the static analysis that exist at the moment.
In Section \ref{sec:ebpfandpcc} we describe an overall design of how we can use PCC in the Linux kernel.
In this section, we further argue for some general design decisions taken in the process of creating the proof-checking part of the PCC system.

** Spelunking the eBPF verifier
:PROPERTIES:
:CUSTOM_ID: sec:verifier
:END:
#+include: ebpf.org

** eBPF and PCC
:PROPERTIES:
:CUSTOM_ID: sec:ebpfandpcc
:END:
From the description of PCC in \ref{sec:pcc} and the description of the eBPF subsystem above,
it should be clear that eBPF and the verifier have some clear similarities with PCC.
eBPF presents a set of security policies, which must be followed to load programs into the kernel.
Likewise, there is a clear distinction between the user space and kernel space or in PCC terminology between code producer and consumer.
Where the current eBPF loading system differs from the PCC described by Necula is where the responsibility lies.
Considering the pipeline we have:

1. *Compilation and Certification*: For PCC the untrusted program is both compiled and a certificate
   for safety policy compliance is generated by the code producer.
   eBPF does not really "do" anything at this stage as source code is passed directly to the kernel using the syscall, and then possibly JIT compiled later in the pipeline.

2. *Verification of certificate*: In PCC the consumer will check the validity of the certification wrt. the safety policy and compatibility between the code and the certificate.
   eBPF will have to do a similar check but directly on the eBPF program.
   From a purely complexity-wise standpoint verification by checking a proof should not be any harder than performing the static analysis done by the verifier.
3. *Running*: In both structures, once a certificate is checked the program is free to use possibly many times.

So if they are so similar in structure, why would we want to replace the verifier with an actual proof checker?
As already mentioned the eBPF verifier has been prone to bugs in the past, and the code for the verifier is characterized by patching of these bugs, instead of implementing a proven sound abstract interpretation.
Having a proof checker that implements a sound approach to proof checking will give a higher certainty in safety as well as more accepted programs because a proof checker does not have to be as conservative as static analysis.

*** How to add PCC to eBPF
To realize PCC in the Linux kernel we must extend it in some way.
There are mainly four ways we can extend the Linux kernel by the documentation\cite{kerneldoc}.
1. If an operation can be achieved using one of the many filesystems already present in the kernel, then it should do so.
2. For device-specific operations, we should consider an LKM.
3. If new functionality is to the kernel it should be in the form of a syscall.
4. If strictly necessary a system call should be modified, but its API should be the same.

The first two options are not really viable solutions for a PCC infrastructure,
since it would require plugging into the subsystem in some way, and this interaction in general seems to break many responsibility patterns and would still require modifying the ~bpf~ syscall.
Option 3 likewise imposes a responsibility mismatch. All interactions with the eBPF subsystem go through the syscall, and having separate system calls to validate the code and load it is not optimal.
Likewise, the proof checker cannot substitute the entire loading process but only the verifier, and probably not all of the checks can be completely removed.
For instance, we might still require capabilities to be checked separately but include memory alignment in the verification condition for the program. On the other hand, capabilities are just boolean flags, which can easily be
represented in logic. Such design decisions would require more experimentation.

The most optimal solution would be to modify the ~bpf~ syscall directly.
We can here also get a partial transition by adding the feature of a proof checker and giving the proof as part of the ~attr~ struct for the syscall.
Then when confidence in the proof checker is high enough the verifier can be phased out.

*** Certifications
:PROPERTIES:
:CUSTOM_ID: sec:certifications
:END:
As previously mentioned we only implement part of PCC in this report,
and this implementation should also just be seen as a prototype.

For the general architecture, we consider a certification format based on formal logic of verification conditions based on predicate transformer semantics\cite{predicatetransformer}.
This is particularly useful for the automatic generation of formulas to describe programs.
The process amount to showing the satisfiability of the negated formula, since this gives validity.
The process of proving the validity of such a verification condition however is not a simple task
and is, depending on the logic, undecidable.
Checking the satisfiability of a formula can be done by a Satisfiability Modulo Theories (SMT) solver.
In some SMT solvers, it is possible to extract a proof that a certain formula is satisfiable.
We have in this work considered two output formats/languages, Alethe\cite{alethe} and Logical Framework with Side Conditions (LFSC)\cite{lfsc},
supported by the CVC5 SMT solver.
I will briefly describe why I have chosen to use the LFSC language over Alethe.

Both formats are based on S-expressions and therefore simple to parse.

Alethe is designed to be easily readable by humans and structured as a box-style proof, with subproofs, conclusions, etc. which make understanding the proofs easy.
This is not a property necessary for a PCC architecture where we want to automate the entire process and do not care about the plain text format, but in fact, rather would want a binary format.
By this construction, the Alethe format provides a set of 91 inference rules\cite{alethe},
on which proofs are built,
As an example, rule 20 is reflection often denoted as ~refl~ which states equality after applying a context.
This entails that an implementation must implement all rules necessary for a security policy and will not be as easily extended in the future as part of a Linux kernel.

LFSC on the other hand is a metaframework that exploits the Curry-Howard isomorphism by dependent type theory.
This meta-framework allows for the security policy to be established by signatures, which encodes similar rules to the ones defined in Alethe.
The meta-framework allows us to implement a simple algorithm for type-checking signatures and verification conditions, which once defined does not have to be changed.
New functionality can then easily be added by new signatures.
Furthermore, this approach can move bugs out of the in-kernel certifier and into the specification.
This will enable system administrators to quickly deploy fixes for a bug, by not allowing specific faulty signatures.

Another important feature of a certification checker in the kernel is that it should be both memory and time efficient.
It is hard to consider both time and memory use of the two languages without actually implementing both of them.
There already exists an implementation for each. LFSC has the /lfscc/ proof checker distributed by CVC5\cite{lfscc}, and Alethe has an unofficial proof checker called /carcara/\cite{carcara}.
We could use these for comparison, but /caracara/ does not support proofs using bit-vectors, which is a must for a proof checker that needs to validate programs with bounded values.
Hence we cannot say anything concrete about the performance of these compared to each other at the given time.

Overall LFSC provides a better basis for the use case.
When using LFSC in the proof checker we suggest that the process of checking that the eBPF program to be loaded corresponds to the proof is done by generating a verification condition and then comparing it to the assertions in the proof.
The specific formula that needs to be proved is directly embedded in an LFSC proof.
Hence we suggest that an in-kernel verification condition generator generates formulas that can easily be compared with the formula from the proof.
This also means that we can reuse some of the code used to implement the proof checker for the VC generation.

# ** Deciding on a format
# #+include: proof_comparison.org
